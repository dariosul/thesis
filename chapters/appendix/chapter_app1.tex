\startappendix{}
\label{chapter:app1}

\section{Solving \ref{eq:3.16}}

% TODO reword as this is too similar to contents of paper 'original.pdf'
Next we show how to compute an exact solution to the SR-LS problem
(\ref{eq:3.16}). Note that \ref{eq:3.16} belongs to the class of problems
consisting of minimizing a quadratic function subject to a single
quadratic constraint. Problems of this type are called generalized trust
region subproblems (GTRS) \cite{More}. GTRS problems, although usually 
nonconvex, possess necessary and sufficient optimality conditions from
which efficient solution methods can be derived. In particular, by 
Theorem 3.2 of \cite{More}, $\By \in R^{n+1}$ is an optimal solution
of \ref{eq:3.16} if and only if there exists $\lambda \in R^{n}$ 
such that

\begin{equation} \label{eq:A.1}
(\BA^{T}\BA + \lambda\BD)\By = \BA^{T}\Bb - \lambda\Bf
\end{equation}

\begin{equation} \label{eq:A.2}
\By^{T}\BD\By + 2\Bf^{T}\By = 0
\end{equation}

\begin{equation} \label{eq:A.3}
\BA^{T}\BA + \lambda\BD \geq 0
\end{equation}

It follows that the optimal solution of \ref{eq:3.16} is given by

\begin{equation} \label{eq:A.4}
\hat{\mathbf{y}}(\lambda) = (\BA^{T}\BA + \lambda\BD)^{-1}(\BA^{T}\Bb - \lambda\Bf)
\end{equation}

where $\lambda$ is the unique solution of

\begin{equation} 
\label{eq:A.5}
\varphi(\lambda) = 0, \lambda \in I
\end{equation}

and the function $\varphi$ is defined by

\begin{equation} \label{eq:A.6}
\varphi(\lambda) \equiv \hat{\mathbf{y}}(\lambda)^{T}\BD\hat{\mathbf{y}}(\lambda) + 2\Bf^{T}\hat{\mathbf{y}}(\lambda)
\end{equation}

The interval $I$ consists of all $\lambda$ for which 
$\BA^{T}\BA + \lambda\BD$ is positive definite, which immediately implies
that 

\begin{equation} \label{eq:A.7}
I = \left(-\dfrac{1}{\lambda_1(\BD,\BA^{T}\BA)}, \infty\right)
\end{equation}

Moreover, it is known by Theorem 5.2 of \cite{More} that
$\varphi(\lambda)$ is strictly decreasing over $I$ and therefore
a simple bisection algorithm can be used to find the optimal $\lambda$
over the interval $I$.

Note that we have limited the discussion to the case in which 
$\BA^{T}\BA + \lambda\BD$ is strictly positive definite, which is
equivalent to saying that the optimal $\lambda$ is different from
$-1/\lambda_1(\BD, \BA^{T}\BA)$. The case in which the optimal $\lambda$
is equal to $-1/\lambda_1(\BD, \BA^{T}\BA)$ is the so-called
``hard case'' of the GRTS problem \cite{FortinWol}, which can 
also be treated by a more refined analysis. However, the value 
$\lambda = -1/\lambda_1(\BD, \BA^{T}\BA)$ 
is very unlikely to occur both theoretically and practically
(it never occurred in the tens of thousands of simulations we 
have performed). Therefore, for the sake of simplicity, we have
tacitly assumed that $\BA^{T}\BA + \lambda\BD$
is positive semi-definite.

The procedure for calculating the SR-LS estimate is summarized next:

a) Use a bisection algorithm to obtain a solution $\lambda$ to (\ref{eq:A.5}).

b) The SR-LS estimate is given by the first $n$ components of the 
vector $\hat{\mathbf{y}}(\lambda)$ in \ref{eq:A.4}.

An alternative approach for computing the SR-LS estimate is considered
in \cite{CheungChan}. The method in \cite{CheungChan} consists of 
finding all the five roots
of the equation $\varphi(\lambda) = 0$ over the real line. This is done
by invoking a root finding procedure for polynomials of degree five.
In a second stage, the global optimal solution of SR-LS is chosen as
the best of the derived possible solutions. Interestingly, in the
above we proved that there is no need to find all the roots of
$\varphi(\lambda) = 0$ and that a simple bisection algorithm is 
sufficient.

\section{Simultaneous Matrix Diagonalization}

\begin{equation} \label{eq:A.5}
\Bv^{T}(\BB^{T}\BB)\Bv = \|\BB\Bv\|^{2} 
\end{equation}

$\BB^{T}\BB$ is at least PSD (full rank), ?? x ??

\begin{equation} \label{eq:A.6}
\BU^{T}\BB^{T}\BB\BU = \begin{bmatrix}
\lambda_1 & & 0 \\
 & \ddots & \\
0 & & \lambda_n
\end{bmatrix}
\end{equation}

$\BU^{T}\BC\BU$ is symmetric.

Non-symmetric square root (of $\BB^{T}\BB$):

\begin{equation} \label{eq:A.7}
\BU\begin{bmatrix}
\sqrt{\lambda_1} & & 0 \\
 & \ddots & \\
0 & & \sqrt{\lambda_n}
\end{bmatrix}
\end{equation}

Symmetric square root:

\begin{equation} \label{eq:A.8}
\BB^{T}\BB = \BU\begin{bmatrix}
\lambda_1 & & 0 \\
 & \ddots & \\
0 & & \lambda_n
\end{bmatrix}\BU^{T} = \BU\begin{bmatrix}
\sqrt{\lambda_1} & & 0 \\
 & \ddots & \\
0 & & \sqrt{\lambda_n}
\end{bmatrix}\BU^{T}\BU\begin{bmatrix}
\sqrt{\lambda_1} & & 0 \\
 & \ddots & \\
0 & & \sqrt{\lambda_n}
\end{bmatrix}\BU^{T}
\end{equation}

i.e.

\begin{equation} \label{eq:A.9}
\BB^{T}\BB = (\BB^{T}\BB)^{1/2}(\BB^{T}\BB)^{1/2}
\end{equation}

\begin{equation} \label{eq:A.10}
\BV(\BB^{T}\BB)^{-1/2}(\BB^{T}\BB)(\BB^{T}\BB)^{-1/2}\BV^{T} = \BV\BI\BV = \begin{bmatrix}
\gamma_1 & & 0 \\
 & \ddots & \\
0 & & \gamma_{n+1}
\end{bmatrix}
\end{equation}

Then for the matrix $\BC$:

\begin{equation} \label{eq:A.11}
\BV(\BB^{T}\BB)^{-1/2}\BC(\BB^{T}\BB)^{-1/2}\BV^{T} = \begin{bmatrix}
\delta_1 & & 0 \\
 & \ddots & \\
0 & & \delta_{n+1}
\end{bmatrix}
\end{equation}

where $\BV$ is orthogonal.

Hence the matrix $\BP$ we seek to compute is given by:

\begin{equation} \label{eq:A.12}
\BP = (\BB^T\BB)^{-1/2}\BV^T
\end{equation}

Share same eigenspace, i.e. the basis of the eigenspace is the same.

\begin{eqnarray}
\BP^{-1}\BA\BP = diag\{\lambda_A\} \\
\nonumber
\BP^{-1}\BB\BP = diag\{\lambda_B\}
\end{eqnarray}

Eigenspace $\BE_{\lambda A}$ of $\BA$ is equivalent to null 
space of $(\BA - \lambda_A\BI)$. 
Hence for $(\BB^T\BB)$ rank = 2 it is true
that

\begin{eqnarray}
\BA = \BV\BLambda_a\BV^T \\
\BB = \BV\BLambda_b\BV^T \\
\BB\BA = \BV\BLambda_b\BV^T\BV\BLambda_a\BV^T = \BV\BLambda_b\BLambda_a\BV^T \\
\Leftrightarrow \BA\BB = \BV\BLambda_a\BLambda_b\BV^T
\end{eqnarray}

for the case when $\BA\BB = \BB\BA$.

\section{Solving \ref{eq:3.32}}

\subsection{Finding roots of the polynomial}

\begin{eqnarray}
\sum^{n+1}_{j=1} \frac{f^2_j\delta_j}{\left(\gamma_j+\lambda\delta_j\right)^2} = 0 \\
\nonumber
\Leftrightarrow \sum^{n+1}_{j=1} f^2_j\delta_j \prod^{n+1}_{k=1,k\neq j}\left(\gamma_k + \lambda_k\delta_k\right)^2 = 0 
\end{eqnarray}
For the planar case, i.e. n = 2
\begin{equation}
\nonumber
\begin{aligned}
& f^2_1\delta_1(1 + \lambda\delta_2)^2(1 + \lambda\delta_3)^2 + f^2_2\delta_2(1 + \lambda\delta_1)^2(1 + \lambda\delta_3)^2 + f^2_3\delta_3(1 + \lambda\delta_2)^2(1 + \lambda\delta_1)^2 \\ 
& = a_0 + \lambda a_1 + \lambda^2 a_2 + \lambda^3 a_3 + \lambda^4 a_4
\end{aligned}
\end{equation}



3.32
